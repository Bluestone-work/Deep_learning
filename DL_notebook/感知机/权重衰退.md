### 使用均方误差作为硬性条件
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923163937.png)
### 使用均方范数进行柔性限制
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923165246.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923165256.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923170015.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923170556.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923170742.png)
由于权重衰减在神经网络优化中很常用， 深度学习框架为了便于我们使用权重衰减， 将权重衰减集成到优化算法中，以便与任何损失函数结合使用。 此外，这种集成还有计算上的好处， 允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。 由于更新的权重衰减部分仅依赖于每个参数的当前值， 因此优化器必须至少接触每个参数一次。
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923171056.png)
![image.png](https://cdn.jsdelivr.net/gh/Bluestone-work/image/image/20240923171107.png)
上图维代码中权重衰退的使用以及效果。
